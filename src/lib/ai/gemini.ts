import { GoogleGenerativeAI } from "@google/generative-ai";
import fs from 'fs/promises';
import path from 'path';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "");

export async function getPrompt(filename: string) {
    try {
        const filePath = path.join(process.cwd(), 'prompts', filename);
        const content = await fs.readFile(filePath, 'utf-8');
        return content;
    } catch (error) {
        console.error(`Error reading prompt ${filename}:`, error);
        return "";
    }
}

export async function generateLanguageContent(promptName: string, variables: Record<string, string>) {
    if (!process.env.GEMINI_API_KEY) {
        throw new Error("‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô Vercel Environment Variables");
    }

    // Use a single, most stable model for now to avoid timeout on fallbacks
    // and explicitly set apiVersion to 'v1'
    const modelName = "gemini-1.5-flash";

    try {
        console.log(`üöÄ Requesting Google AI with model: ${modelName}`);

        // Explicitly use v1 API which is more stable than v1beta
        const model = genAI.getGenerativeModel(
            { model: modelName },
            { apiVersion: 'v1' }
        );

        const systemPrompt = await getPrompt('00_system_core.txt');
        let targetPrompt = await getPrompt(promptName);

        for (const [key, value] of Object.entries(variables)) {
            targetPrompt = targetPrompt.replace(new RegExp(`{{${key}}}`, 'g'), value);
        }

        const combinedPrompt = `${systemPrompt}\n\n${targetPrompt}`;

        const result = await model.generateContent(combinedPrompt);
        const response = await result.response;
        let text = response.text();

        // Clean up JSON formatting
        if (text.includes('```json')) {
            text = text.split('```json')[1].split('```')[0];
        } else if (text.includes('```')) {
            text = text.split('```')[1].split('```')[0];
        }

        return JSON.parse(text.trim());

    } catch (error: any) {
        console.error(`‚ùå AI Generation Error:`, error);

        let errorMessage = error.message || "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI";

        if (errorMessage.includes('404')) {
            errorMessage = `‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• ${modelName} (404). ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå Gemini 1.5 ‡πÅ‡∏•‡πâ‡∏ß`;
        } else if (errorMessage.includes('429')) {
            errorMessage = "‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ API ‡πÄ‡∏ï‡πá‡∏°‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà";
        } else if (errorMessage.includes('API key not valid')) {
            errorMessage = "API Key ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô Vercel";
        }

        throw new Error(errorMessage);
    }
}
